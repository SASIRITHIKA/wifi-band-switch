'''
triband_ann_who_highacc_v3.py
Enhanced ANN + WHO Optimization for Tri-band WiFi Switching (2.4 / 5 / 6 GHz)
Modified for aggressive high accuracy (~99.99%)
'''

# --------------------- auto-install required packages ---------------------
import importlib, subprocess, sys, os
REQUIRED = ["numpy", "pandas", "matplotlib", "scikit-learn", "tensorflow", "joblib"]
for pkg in REQUIRED:
    try:
        importlib.import_module(pkg)
    except Exception:
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])

# --------------------- imports ---------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings, time, random
warnings.filterwarnings("ignore")
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, confusion_matrix, f1_score,
    roc_curve, auc, precision_recall_curve, average_precision_score,
    precision_score, recall_score
)
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
import joblib

# --------------------- user settings ---------------------
CSV_PATH = "wifi_dataset.csv"   # dataset path
TEST_SIZE = 0.2
VAL_SIZE = 0.15
RANDOM_STATE = 42

WHO_POP = 12      # larger population
WHO_ITERS = 10    # more iterations for better tuning

np.random.seed(RANDOM_STATE)
tf.random.set_seed(RANDOM_STATE)

# --------------------- helper functions ---------------------
def build_ann(input_dim, num_classes, hidden1=128, hidden2=64, dropout=0.1, lr=1e-3):
    model = models.Sequential()
    model.add(layers.Input(shape=(input_dim,)))
    model.add(layers.Dense(hidden1, activation='relu'))
    model.add(layers.Dense(hidden2, activation='relu'))
    model.add(layers.Dropout(dropout))
    model.add(layers.Dense(num_classes, activation='softmax'))
    opt = optimizers.Adam(learning_rate=lr)
    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def particle_to_hparams(p):
    h1 = int(np.clip(p[0], 64, 256))
    h2 = int(np.clip(p[1], 32, 128))
    dropout = float(np.clip(p[2], 0.05, 0.2))    # very small dropout
    lr_exp = float(np.clip(p[3], -5.0, -3.0))
    lr = 10.0 ** lr_exp
    batch = int(2 ** int(np.round(np.clip(p[4], 4, 8))))
    return dict(hidden1=h1, hidden2=h2, dropout=dropout, lr=lr, batch=batch)

def make_fitness(X_train, y_train, X_val, y_val, input_dim, num_classes, max_epochs=10):
    cache = {}
    def fitness_fn(p):
        key = tuple(np.round(p, 3))
        if key in cache:
            return cache[key]
        h = particle_to_hparams(p)
        model = build_ann(input_dim, num_classes, hidden1=h['hidden1'],
                          hidden2=h['hidden2'], dropout=h['dropout'], lr=h['lr'])
        es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)
        model.fit(X_train, y_train, validation_data=(X_val, y_val),
                  epochs=max_epochs, batch_size=h['batch'], verbose=0, callbacks=[es])
        loss, _ = model.evaluate(X_val, y_val, verbose=0)
        tf.keras.backend.clear_session()
        cache[key] = loss
        return loss
    return fitness_fn

def who_optimize(fitness_fn, dim, lb, ub, n_wolves=WHO_POP, iters=WHO_ITERS):
    pop = np.random.uniform(lb, ub, (n_wolves, dim))
    fitness = np.array([fitness_fn(ind) for ind in pop])
    best_idx = np.argmin(fitness)
    best_pos = pop[best_idx]
    best_fit = fitness[best_idx]

    for t in range(iters):
        for i in range(n_wolves):
            for j in range(dim):
                r1, r2 = np.random.rand(), np.random.rand()
                A = 2*r1 - 1
                C = 2*r2
                D = abs(C*best_pos[j] - pop[i,j])
                pop[i,j] = best_pos[j] - A*D
            pop[i] = np.clip(pop[i], lb, ub)
            fitness[i] = fitness_fn(pop[i])

        best_idx = np.argmin(fitness)
        best_pos = pop[best_idx]
        best_fit = fitness[best_idx]
        print(f"Iter {t+1}/{iters} best loss={best_fit:.6f}")
    return best_pos, best_fit

def plot_roc_pr(y_test_onehot, y_score, classes):
    n_classes = y_test_onehot.shape[1]
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    for i in range(n_classes):
        fpr, tpr, _ = roc_curve(y_test_onehot[:, i], y_score[:, i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f"{classes[i]} (AUC={roc_auc:.3f})")
    plt.plot([0,1],[0,1],'k--'); plt.title("ROC Curves"); plt.xlabel("FPR"); plt.ylabel("TPR"); plt.legend(fontsize=8)

    plt.subplot(1,2,2)
    for i in range(n_classes):
        prec, rec, _ = precision_recall_curve(y_test_onehot[:, i], y_score[:, i])
        ap = average_precision_score(y_test_onehot[:, i], y_score[:, i])
        plt.plot(rec, prec, label=f"{classes[i]} (AP={ap:.3f})")
    plt.title("Precision-Recall Curves"); plt.xlabel("Recall"); plt.ylabel("Precision"); plt.legend(fontsize=8)
    plt.tight_layout()
    plt.show()

# --------------------- main pipeline ---------------------
def main():
    # CSV handling
    csv_path = CSV_PATH
    try:
        import google.colab
        from google.colab import files
        print("Detected Colab â€” please upload CSV:")
        uploaded = files.upload()
        if uploaded:
            csv_path = next(iter(uploaded.keys()))
            print("Uploaded:", csv_path)
    except Exception:
        pass
    if not os.path.exists(csv_path):
        print(f"CSV not found at {csv_path}")
        return

    df = pd.read_csv(csv_path).dropna().reset_index(drop=True)
    print("Dataset shape:", df.shape)

    X_df = df.iloc[:, :-1].copy()
    y_raw = df.iloc[:, -1].values

    # encode categorical features
    for col in X_df.select_dtypes(exclude=[np.number]).columns:
        X_df[col] = LabelEncoder().fit_transform(X_df[col].astype(str))
    X = X_df.values

    # encode labels
    le = LabelEncoder()
    y_enc = le.fit_transform(y_raw)
    num_classes = len(le.classes_)
    y_onehot = tf.keras.utils.to_categorical(y_enc, num_classes)

    # scale features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # train/val/test split
    X_trainval, X_test, y_trainval, y_test = train_test_split(
        X_scaled, y_onehot, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_enc
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_trainval, y_trainval, test_size=VAL_SIZE, random_state=RANDOM_STATE,
        stratify=np.argmax(y_trainval, axis=1)
    )
    input_dim = X.shape[1]

    # WHO optimization for hyperparameters
    print("Running WHO optimization...")
    lb = np.array([64,32,0.05,-5.0,4.0])
    ub = np.array([256,128,0.2,-3.0,8.0])
    fitness_fn = make_fitness(X_train, y_train, X_val, y_val, input_dim, num_classes, max_epochs=10)
    best_pos, best_loss = who_optimize(fitness_fn, dim=len(lb), lb=lb, ub=ub, n_wolves=WHO_POP, iters=WHO_ITERS)
    best_h = particle_to_hparams(best_pos)
    print("Best hyperparameters:", best_h)

    # train final model
    final_model = build_ann(input_dim, num_classes,
                            hidden1=best_h['hidden1'], hidden2=best_h['hidden2'],
                            dropout=best_h['dropout'], lr=best_h['lr'])
    cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    history = final_model.fit(
        X_trainval, y_trainval, validation_data=(X_val, y_val),
        epochs=100, batch_size=best_h['batch'], callbacks=[cb], verbose=1
    )

    # evaluate
    test_loss, test_acc = final_model.evaluate(X_test, y_test, verbose=0)
    y_score = final_model.predict(X_test)
    y_pred = np.argmax(y_score, axis=1)
    y_true = np.argmax(y_test, axis=1)

    print("\n=== MODEL METRICS ===")
    print(f"Test Loss      : {test_loss:.6f}")
    print(f"Test Accuracy  : {test_acc:.6f}")
    print(f"Error Rate     : {1.0-test_acc:.6f}")
    print(f"Macro F1 Score : {f1_score(y_true,y_pred,average='macro'):.6f}")
    print(f"Macro Precision: {precision_score(y_true,y_pred,average='macro'):.6f}")
    print(f"Macro Recall   : {recall_score(y_true,y_pred,average='macro'):.6f}")
    print("Confusion Matrix:\n", confusion_matrix(y_true,y_pred))

    plot_roc_pr(y_test, y_score, le.classes_)

if __name__ == "__main__":
    main()
\
